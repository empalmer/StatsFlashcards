\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm}
\newenvironment{note}{\paragraph{NOTE:}}{}
\newenvironment{field}{\paragraph{field:}}{}
%\newenvironment{tags}{\paragraph{tags:}}{}
\newcommand*{\tags}[1]{\paragraph{tags: }#1}

\begin{document}

%%start_tag From Stat Cheatsheet
\tags{FromStatCheatsheet statcheet}

\begin{note}
  \begin{field}
    CDF of Geometric ($p$)
  \end{field}
  \begin{field}
    $1 - (1-p)^x$
  \end{field}
\end{note}


\begin{note}
  \begin{field}
    CDF of Exponential($\beta$)
  \end{field}
  \begin{field}
    $1 - e^{-\frac{x}{\beta}}$
  \end{field}
\end{note}

\begin{note}
  \begin{field}
    \begin{itemize}
  \item $P(\varnothing) = $
  \item $B = \Omega \cap B = (A \cup A^c) \cap B
    = (A \cap B) \cup (A^c \cap B)$
  \item $P(A^c) = $
  \item $P(B) = $
  \item $P(\Omega) =  \qquad P(\varnothing) = $
  \item $\left(\bigcup_n A_n\right) =
    \quad
    \left(\bigcap_n A_n\right) =
    \qquad$
    \textsc{DeMorgan}
\end{itemize}
  \end{field}
  \begin{field}
    \begin{itemize}
  \item $P(\varnothing) = 0$
  \item $B = \Omega \cap B = (A \cup A^c) \cap B
    = (A \cap B) \cup (A^c \cap B)$
  \item $P(A^c) = 1 - P(A)$
  \item $P(B) = P(A \cap B) + P(A^c \cap B)$
  \item $P(\Omega) = 1 \qquad P(\varnothing) = 0$
  \item $\left(\bigcup_n A_n\right) = \bigcap_n A_n
    \quad
    \left(\bigcap_n A_n\right) = \bigcup_n A_n
    \qquad$
    \textsc{DeMorgan}
\end{itemize}
  \end{field}
\end{note}




\begin{note}
  \begin{field}
    Probability Set intersection
    \begin{itemize}
      \item $P(\bigcup_n A_n)
        = 1 - P(\bigcap_n A_n^c)$
      \item $P(A \cup B) = P(A) + P(B) - P(A \cap B)
        \implies P(A \cup B) \leq P(A) + P(B)$
      \item $P(A \cup B)
        = $
      \item $P(A \cap B^c) = $
    \end{itemize}
  \end{field}
  \begin{field}
    Probability Set intersection
    \begin{itemize}
      \item $P(\bigcup_n A_n)
        = 1 - P(\bigcap_n \mathsf{A_n})$
      \item $P(A \cup B) = P(A) + P(B) - P(A \cap B)\\[1ex]
        \implies P(A \cup B) \le P(A) + P(B)$
      \item $P(A \cup B)
        = P(A \cap B^c) + P(A^c \cap B) + P(A \cap B)$
      \item $P(A \cap B^c) = P(A) - P(A \cap B)$
    \end{itemize}
  \end{field}
\end{note}

\begin{note}
  \begin{field}
    $P(A \cap B) =  \text{ when }A \text{ and } B \text{independent}$
  \end{field}
  \begin{field}
    $P(A \cap B) = P(A)P(B) \text{ when }A \text{ and } B \text{independent}$
  \end{field}
  \end{note}

\begin{note}
  \begin{field}
    $$P(A|B) = $$
  \end{field}
  \begin{field}
    $$P(A|B) = \frac{P(A\cap B)}{P(B)}$$
  \end{field}
\end{note}

\begin{note}
  \begin{field}
    Law of total probability
  \end{field}
  \begin{field}
    Law of total probability
    $$P(B) = \sum_{i=1}^n P(B|A_i)P(A_i) \quad \Omega = \cup_{i=1}^n A_i$$

    $$P(B) = P(A \cup B) + P(A^c \cup B) $$
   \end{field}
\end{note}

\begin{note}
  \begin{field}
    Bayes Theorem
  \end{field}
  \begin{field}
    Bayes Theorem
    $$P(A_i|B) = \frac{P(B|A_i)P(A_i)}{\sum_{j=1}^n P(B|A_j)P(A_j)} \quad \Omega = \cup_{i=1}^n A_i$$
  \end{field}
\end{note}

\begin{note}
  \begin{field}
    CDF Laws
  \end{field}
  \begin{field}
    CDF Laws
    \begin{enumerate}
      \item Nondecreasing: $x_1 < x_2 \implies F(x_1) \leq F(x_2)$
      \item Limits: $\lim_{x \to -\infty}=0$ and $\lim_{x\to \infty} = 1$
      \item Right-Continuous $\lim_{y \to x^+}F(y) = F(x)$
    \end{enumerate}
  \end{field}
\end{note}

\begin{note}
  \begin{field}
    $$f_{y|x}(y|x) = $$
  \end{field}
  \begin{field}
    $$f_{y|x}(y|x) = \frac{f(x,y)}{f_x(x)}$$
  \end{field}
\end{note}

\begin{note}
  \begin{field}
    $X,Y \text{independent}$
    \begin{itemize}
      \item $P(X \leq x, Y \leq y) = $
      \item $f_{x,y}(x,y) = $
    \end{itemize}
  \end{field}
  \begin{field}
    $X,Y \text{independent}$
    \begin{itemize}
      \item $P(X \leq x, Y \leq y) = P(X \leq x)P(Y \leq y)$
      \item $f_{x,y}(x,y) = f_x(x)f_y(y)$
    \end{itemize}
  \end{field}
\end{note}

\begin{note}
  \begin{field}
     Transformations $Z = \phi(X)$

    \begin{itemize}
      \item Discrete: $f_Z(z) = $
      \item Continuous: $F_Z(z)=$
      \item Cont, $\phi$ strictly monotone:
      $f_z(z)$
    \end{itemize}
  \end{field}
  \begin{field}
    Transformations $Z = \phi(X)$
  \begin{itemize}
    \item Discrete: $$f_Z(z) = P(\phi(X) = z) = P(X \in \phi^{-1}(z)) = \sum_{x \in \phi^{-1}(z)}f_x(x) $$
    \item Continuous (Method of CDF): $$F_Z(z)= P(\phi(X)\leq z) = \int_{x:\phi(x)\leq z} f(x) dx$$
    \item Cont, $\phi$ strictly monotone: (Method of PDF)
    $f_z(z) = f_x(\phi^{-1}(z))|\frac{d}{dz} \phi^{-1}(z)|$
  \end{itemize}
\end{field}
\end{note}

\begin{note}
  \begin{field}
     Rule of the Lazy Statistician: $ E[g(x)] = $
  \end{field}
  \begin{field}
    Rule of the Lazy Statistician:  $E[g(x)] = \int g(x)f_x(x)dx$
  \end{field}
\end{note}

\begin{note}
  \begin{field}
    Expectation rules
    \begin{itemize}
      \item $E(c) = $
      \item $E(cX) = $
      \item $E(X + Y) = $
      \item $E(\phi(X)) = $
    \end{itemize}
  \end{field}
  \begin{field}
    Expectation rules
    \begin{itemize}
      \item $E(c) = c$
      \item $E(cX) = cE(X)$
      \item $E(X + Y) = E(X) + E(Y)$
      \item $E(\phi(X)) \neq \phi(E(X))$
    \end{itemize}
  \end{field}
\end{note}

\begin{note}
  \begin{field}
    Conditional expectation
      \begin{itemize}
        \item $E(Y|X = x) = $
        \item $E(X) = $
        \item $E(Y+Z|X) = $
        \item $E(Y|X) = c \implies $
      \end{itemize}
  \end{field}
  \begin{field}
    Conditional expectation
      \begin{itemize}
        \item $E(Y|X = x) = \int y f(y|x) dy$
        \item $E(X) = E(E(X|Y))$
        \item $E(Y+Z|X) = E(Y|X) + E(Z|X)$
        \item $E(Y|X) = c \implies Cov(X,Y) = 0$
      \end{itemize}

  \end{field}
\end{note}


\begin{note}
  \begin{field}
    Variance
    \begin{itemize}
      \item $V(X) = \sigma_x^2 = $
      \item $V(X+Y) =$
      \item $V\bigg[\sum_{i=1}^n X_i\bigg] = $
    \end{itemize}
  \end{field}
  \begin{field}
    Variance
    \begin{itemize}
      \item $V(X) = \sigma_x^2 = E[(X - E(X))^2] = E(X^2) - E(X)^2$
      \item $V(X+Y) = V(X) + V(Y) + Cov(X,Y)$
      \item $V\bigg[\sum_{i=1}^n X_i\bigg] = \sum_{i=1}^n V(X_i) + \sum_{i\neq j} Cov(X_i,X_j)$
    \end{itemize}
  \end{field}
\end{note}








\begin{note}
  \begin{field}
    Covariance
    \begin{itemize}
      \item $Cov(X,Y) = $
      \item $Cov(X,c) = $
      \item $Cov(Y,X) = $
      \item $Cov(aX,bY) =$
      \item $Cov(X + a, Y + b) =$
      \item $Cov\bigg(\sum_{i=1}^n X_i, \sum_{j=1}^m Y_j\bigg) = $
    \end{itemize}
  \end{field}
  \begin{field}
    Covariance
    \begin{itemize}
      \item $Cov(X,Y) = E[(X - E(X)(Y - E(Y)))] = E(XY) - E(X)E(Y)$
      \item $Cov(X,c) = 0$
      \item $Cov(Y,X) = Cov(X,Y)$
      \item $Cov(aX,bY) = abCov(X,Y)$
      \item $Cov(X + a, Y + b) = Cov(X,Y)$
      \item $Cov\bigg(\sum_{i=1}^n X_i, \sum_{j=1}^m Y_j\bigg) = \sum_{i=1}^n \sum_{j=1}^m Cov(X_i,Y_j)$
    \end{itemize}
  \end{field}
\end{note}

\begin{note}
  \begin{field}
    Correlation: $\rho(X,Y)$
  \end{field}
  \begin{field}
    Correlation: $\rho(X,Y) = \frac{Cov(X,Y)}{\sqrt{V(X)V(Y)}}$
  \end{field}
\end{note}



\begin{note}
  \begin{field}
    Conditional Variance
    \begin{itemize}
      \item $V(Y|X) = $
      \item $V(Y) = $
    \end{itemize}
  \end{field}
  \begin{field}
    Conditional Variance
    \begin{itemize}
      \item $V(Y|X) = E\big[(Y - E(Y|X))^2|X\big] = E(Y^2|X) - E(Y|X)^2$
      \item $V(Y) = E(V(Y|X)) + V(E(Y|X))$
    \end{itemize}
  \end{field}
\end{note}

%%end_tag

\end{document}
